{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "RANDOM_STATE=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                               text  toxic\n",
       " 0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       " 1           1  D'aww! He matches this background colour I'm s...      0\n",
       " 2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       " 3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       " 4           4  You, sir, are my hero. Any chance you remember...      0,\n",
       " None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим наличие пропусков\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на наличие явных дубликатов\n",
    "\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как перед нами задачи классификации, необходимо посмотреть на сбалансированность классов в целевом признаке **data['toxic']**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы не сбалансированы, перед обучением данных нужно это исправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Лемматизируем исходный текст\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(text):\n",
    "    tag = nltk.pos_tag([text])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemma_text(text):\n",
    "    text = text.lower()\n",
    "    lemm_text = \"\".join(lemmatizer.lemmatize(text, get_wordnet_pos(text)))\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())\n",
    "\n",
    "data['lemm_text'] = data['text'].apply(lemma_text)\n",
    "\n",
    "#Создадим новый датафрейм без столбца text\n",
    "\n",
    "data_clear = data.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  toxic                                          lemm_text\n",
       "0           0      0  explanation why the edits made under my userna...\n",
       "1           1      0  d aww he matches this background colour i m se...\n",
       "2           2      0  hey man i m really not trying to edit war it s...\n",
       "3           3      0  more i can t make any real suggestions on impr...\n",
       "4           4      0  you sir are my hero any chance you remember wh..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на выборки, а затем напишем функцию upsample для балансировки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_clear['lemm_text']\n",
    "target = data_clear['toxic']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              train_size=0.7, \n",
    "                                                                              random_state=RANDOM_STATE)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=0.5,\n",
    "                                                                            random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Напишем функцию upsample для балансировки классов\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=RANDOM_STATE)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Сбалансируем данные\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73125\n",
       "0    71521\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверим балансировку\n",
    "\n",
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем текст в TF-IDF векторы для моделей\n",
    "\n",
    "stopwordss = set(stopwords.words('english'))\n",
    "\n",
    "count_tf = TfidfVectorizer(stop_words = stopwordss, use_idf=True)\n",
    "\n",
    "features_train = count_tf.fit_transform(features_upsampled)\n",
    "features_valid = count_tf.transform(features_valid)\n",
    "features_test = count_tf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "Загрузили данные и подготовили их для обучения моделей. \n",
    "\n",
    "Данные содержат 2 столбца:\n",
    "\n",
    "**text** — текст комментариев;\n",
    "\n",
    "**toxic** — хранит информацию о комментариях: токсичный (1) и положительный (0) комментарии.\n",
    "\n",
    "Пропусков и явных дубликатов не обнаружено, в целевом признаке классы не сбалансированы.\n",
    "\n",
    "Лемматизировали исходный текст. Разбили данные на 2 выборки: обучающую и тестовую. Произвели балансировку классов, а затем преобразовали текст в TF-IDF векторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подберем параметры для модели \n",
    "\n",
    "#model_lr = LogisticRegression()\n",
    "\n",
    "#param = {'C':[10], 'random_state':[RANDOM_STATE]}\n",
    "\n",
    "#model_lr_grid = GridSearchCV(model_lr, param, scoring='f1', cv=3)\n",
    "#model_lr_grid.fit(features_train, target_upsampled)\n",
    "\n",
    "#print('F1:', model_lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7670866743031692\n"
     ]
    }
   ],
   "source": [
    "#Обучим модель и вычислим значение метрики f1\n",
    "\n",
    "model_lr = LogisticRegression(C=10, random_state=RANDOM_STATE)\n",
    "model_lr.fit(features_train, target_upsampled)\n",
    "\n",
    "prediction = model_lr.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подберем параметры для модели \n",
    "\n",
    "#model_rf = RandomForestClassifier()\n",
    "\n",
    "#param = {'n_estimators': range(1,50,5),'max_depth': range(1,15,3)}\n",
    "\n",
    "#model_rf_grid = GridSearchCV(model_rf, param, scoring=r'f1', cv=3)\n",
    "#model_rf_grid.fit(features_train, target_upsampled)\n",
    "\n",
    "#print(model_rf_grid.best_params_)\n",
    "\n",
    "#print('F1:', model_rf_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.35199870529211846\n"
     ]
    }
   ],
   "source": [
    "#Обучим модель и вычислим значение метрики f1\n",
    "\n",
    "model_rf = RandomForestClassifier(max_depth=13, n_estimators=46, random_state=RANDOM_STATE)\n",
    "model_rf.fit(features_train, target_upsampled)\n",
    "\n",
    "prediction = model_rf.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7479733381372726\n"
     ]
    }
   ],
   "source": [
    "#Обучим модель и вычислим значение метрики f1\n",
    "\n",
    "model_lgbm = LGBMClassifier(num_leaves=100, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "model_lgbm.fit(features_train, target_upsampled)\n",
    "\n",
    "prediction = model_lgbm.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5435533\ttotal: 3.97s\tremaining: 3m 54s\n",
      "1:\tlearn: 0.4938819\ttotal: 7.19s\tremaining: 3m 28s\n",
      "2:\tlearn: 0.4608281\ttotal: 10.5s\tremaining: 3m 19s\n",
      "3:\tlearn: 0.4376219\ttotal: 13.8s\tremaining: 3m 13s\n",
      "4:\tlearn: 0.4192844\ttotal: 17.1s\tremaining: 3m 7s\n",
      "5:\tlearn: 0.4041569\ttotal: 20.4s\tremaining: 3m 3s\n",
      "6:\tlearn: 0.3921997\ttotal: 23.6s\tremaining: 2m 58s\n",
      "7:\tlearn: 0.3807499\ttotal: 26.9s\tremaining: 2m 54s\n",
      "8:\tlearn: 0.3708438\ttotal: 30.1s\tremaining: 2m 50s\n",
      "9:\tlearn: 0.3626015\ttotal: 33.3s\tremaining: 2m 46s\n",
      "10:\tlearn: 0.3558703\ttotal: 36.6s\tremaining: 2m 42s\n",
      "11:\tlearn: 0.3497236\ttotal: 39.7s\tremaining: 2m 38s\n",
      "12:\tlearn: 0.3445164\ttotal: 42.9s\tremaining: 2m 35s\n",
      "13:\tlearn: 0.3394178\ttotal: 46s\tremaining: 2m 31s\n",
      "14:\tlearn: 0.3346800\ttotal: 49s\tremaining: 2m 26s\n",
      "15:\tlearn: 0.3301049\ttotal: 52.2s\tremaining: 2m 23s\n",
      "16:\tlearn: 0.3241810\ttotal: 55.6s\tremaining: 2m 20s\n",
      "17:\tlearn: 0.3195453\ttotal: 58.8s\tremaining: 2m 17s\n",
      "18:\tlearn: 0.3151646\ttotal: 1m 1s\tremaining: 2m 13s\n",
      "19:\tlearn: 0.3113449\ttotal: 1m 5s\tremaining: 2m 10s\n",
      "20:\tlearn: 0.3076490\ttotal: 1m 8s\tremaining: 2m 6s\n",
      "21:\tlearn: 0.3049379\ttotal: 1m 11s\tremaining: 2m 2s\n",
      "22:\tlearn: 0.3017370\ttotal: 1m 14s\tremaining: 1m 59s\n",
      "23:\tlearn: 0.2993249\ttotal: 1m 17s\tremaining: 1m 55s\n",
      "24:\tlearn: 0.2965115\ttotal: 1m 20s\tremaining: 1m 52s\n",
      "25:\tlearn: 0.2930313\ttotal: 1m 22s\tremaining: 1m 48s\n",
      "26:\tlearn: 0.2895751\ttotal: 1m 26s\tremaining: 1m 45s\n",
      "27:\tlearn: 0.2869759\ttotal: 1m 29s\tremaining: 1m 42s\n",
      "28:\tlearn: 0.2848242\ttotal: 1m 32s\tremaining: 1m 38s\n",
      "29:\tlearn: 0.2829651\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "30:\tlearn: 0.2807512\ttotal: 1m 37s\tremaining: 1m 31s\n",
      "31:\tlearn: 0.2789826\ttotal: 1m 40s\tremaining: 1m 28s\n",
      "32:\tlearn: 0.2772851\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "33:\tlearn: 0.2755627\ttotal: 1m 46s\tremaining: 1m 21s\n",
      "34:\tlearn: 0.2732765\ttotal: 1m 49s\tremaining: 1m 18s\n",
      "35:\tlearn: 0.2710773\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "36:\tlearn: 0.2691158\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "37:\tlearn: 0.2678597\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "38:\tlearn: 0.2659633\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "39:\tlearn: 0.2630258\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "40:\tlearn: 0.2609764\ttotal: 2m 7s\tremaining: 59.1s\n",
      "41:\tlearn: 0.2597757\ttotal: 2m 10s\tremaining: 55.8s\n",
      "42:\tlearn: 0.2572990\ttotal: 2m 13s\tremaining: 52.6s\n",
      "43:\tlearn: 0.2551241\ttotal: 2m 16s\tremaining: 49.5s\n",
      "44:\tlearn: 0.2540094\ttotal: 2m 19s\tremaining: 46.3s\n",
      "45:\tlearn: 0.2524756\ttotal: 2m 21s\tremaining: 43.1s\n",
      "46:\tlearn: 0.2508719\ttotal: 2m 25s\tremaining: 40.1s\n",
      "47:\tlearn: 0.2490834\ttotal: 2m 28s\tremaining: 37s\n",
      "48:\tlearn: 0.2472998\ttotal: 2m 31s\tremaining: 33.9s\n",
      "49:\tlearn: 0.2463440\ttotal: 2m 33s\tremaining: 30.8s\n",
      "50:\tlearn: 0.2451380\ttotal: 2m 36s\tremaining: 27.7s\n",
      "51:\tlearn: 0.2431336\ttotal: 2m 39s\tremaining: 24.6s\n",
      "52:\tlearn: 0.2419979\ttotal: 2m 42s\tremaining: 21.5s\n",
      "53:\tlearn: 0.2410372\ttotal: 2m 45s\tremaining: 18.4s\n",
      "54:\tlearn: 0.2400809\ttotal: 2m 48s\tremaining: 15.3s\n",
      "55:\tlearn: 0.2388295\ttotal: 2m 51s\tremaining: 12.2s\n",
      "56:\tlearn: 0.2379270\ttotal: 2m 53s\tremaining: 9.15s\n",
      "57:\tlearn: 0.2365249\ttotal: 2m 56s\tremaining: 6.1s\n",
      "58:\tlearn: 0.2347444\ttotal: 3m\tremaining: 3.05s\n",
      "59:\tlearn: 0.2337600\ttotal: 3m 2s\tremaining: 0us\n",
      "F1: 0.6999656711294199\n"
     ]
    }
   ],
   "source": [
    "#Обучим модель и вычислим значение метрики f1\n",
    "\n",
    "model_cat = CatBoostClassifier(depth=6, iterations=60, learning_rate=0.9)\n",
    "model_cat.fit(features_train, target_upsampled)\n",
    "\n",
    "prediction = model_cat.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моделям LGBMClassifier и CatBoostClassifier я также пыталась подобрать гиперпараметры, но слетало с dead kernel, поэтому взяла значения из прошлого проекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Метрика f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.7670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.7479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.6990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Метрика f1\n",
       "LogisticRegression          0.7670\n",
       "RandomForestClassifier      0.3519\n",
       "LGBMClassifier              0.7479\n",
       "CatBoostClassifier          0.6990"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Выведем таблицу с результатами моделей\n",
    "\n",
    "data_tabl=[0.7670, 0.3519, 0.7479, 0.699]\n",
    "model_tabl=['LogisticRegression', 'RandomForestClassifier', 'LGBMClassifier', 'CatBoostClassifier']\n",
    "\n",
    "pd.DataFrame(data=data_tabl, index=model_tabl, columns=['Метрика f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение метрики f1 (0.7670) у модели LogisticRegression. Посмотрим результат на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7611881188118812\n"
     ]
    }
   ],
   "source": [
    "#Вычислим значение метрики f1 на тестовой выборке\n",
    "\n",
    "prediction = model_lr.predict(features_test)\n",
    "\n",
    "print('F1:', f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.18324209245742093\n"
     ]
    }
   ],
   "source": [
    "#Вычислим f1 констатной модели\n",
    "\n",
    "model_const = DummyClassifier(strategy=\"most_frequent\")\n",
    "model_const.fit(features_train, target_upsampled)\n",
    "\n",
    "prediction = model_const.predict(features_test)\n",
    "\n",
    "print('F1:', f1_score(target_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По условию задачи нужно было построить модель со значением метрики качества F1 не меньше 0.75. Мы рассмотрели следующие модели:\n",
    "\n",
    "1. LogisticRegression;\n",
    "\n",
    "2. RandomForestClassifier;\n",
    "\n",
    "3. LGBMClassifier;\n",
    "\n",
    "4. CatBoostClassifier.\n",
    "\n",
    "Мы достигли метрики f1=0.7611 на тестовой выборке у модели LogisticRegression. В сравнении с константной моделью, она адекватна. Ближе всего к установленному порогу оказалась модель LGBMClassifier, на валидационной выборке её метрика f1=0.7479. Эта модель, как и остальные, в сравнении с константной моделью оказалась адекватной. Худший результат показала модель RandomForestClassifier со значением 0.3519."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1885,
    "start_time": "2023-08-09T19:10:35.900Z"
   },
   {
    "duration": 3636,
    "start_time": "2023-08-09T19:11:21.118Z"
   },
   {
    "duration": 988,
    "start_time": "2023-08-09T19:14:51.098Z"
   },
   {
    "duration": 1153,
    "start_time": "2023-08-09T19:16:40.149Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-09T19:17:19.625Z"
   },
   {
    "duration": 240,
    "start_time": "2023-08-09T19:19:04.290Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-09T19:21:58.793Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-09T19:22:20.703Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-09T19:47:40.553Z"
   },
   {
    "duration": 10142,
    "start_time": "2023-08-09T19:49:52.228Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-09T19:50:27.335Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-09T20:05:31.997Z"
   },
   {
    "duration": 129,
    "start_time": "2023-08-09T20:05:58.804Z"
   },
   {
    "duration": 53,
    "start_time": "2023-08-09T20:06:19.669Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:08:24.704Z"
   },
   {
    "duration": 47,
    "start_time": "2023-08-09T20:08:42.830Z"
   },
   {
    "duration": 30,
    "start_time": "2023-08-09T20:09:33.645Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:09:36.863Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-09T20:09:40.713Z"
   },
   {
    "duration": 539,
    "start_time": "2023-08-09T20:11:45.546Z"
   },
   {
    "duration": 53,
    "start_time": "2023-08-09T20:11:56.426Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:12:25.591Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-09T20:12:56.290Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:16:09.973Z"
   },
   {
    "duration": 56,
    "start_time": "2023-08-09T20:16:25.389Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:16:46.240Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-09T20:16:55.728Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-09T20:16:58.051Z"
   },
   {
    "duration": 68,
    "start_time": "2023-08-09T20:17:05.117Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:17:10.906Z"
   },
   {
    "duration": 235,
    "start_time": "2023-08-09T20:17:24.808Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-09T20:17:39.434Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-09T20:19:21.215Z"
   },
   {
    "duration": 108,
    "start_time": "2023-08-09T20:19:23.990Z"
   },
   {
    "duration": 71,
    "start_time": "2023-08-09T20:19:33.325Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-09T20:19:35.366Z"
   },
   {
    "duration": 74,
    "start_time": "2023-08-09T20:19:43.473Z"
   },
   {
    "duration": 71,
    "start_time": "2023-08-09T20:19:52.303Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-09T20:19:54.526Z"
   },
   {
    "duration": 115,
    "start_time": "2023-08-09T20:19:59.882Z"
   },
   {
    "duration": 67,
    "start_time": "2023-08-09T20:20:08.194Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-09T20:20:12.524Z"
   },
   {
    "duration": 87,
    "start_time": "2023-08-09T20:20:19.497Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-09T20:20:22.474Z"
   },
   {
    "duration": 78,
    "start_time": "2023-08-09T20:20:30.563Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-09T20:20:34.917Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-09T20:27:40.002Z"
   },
   {
    "duration": 8670,
    "start_time": "2023-08-09T20:27:41.844Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-09T20:28:48.633Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-09T20:29:37.375Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-09T20:30:17.544Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-09T20:30:45.597Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T20:30:54.483Z"
   },
   {
    "duration": 2345,
    "start_time": "2023-08-10T16:02:05.802Z"
   },
   {
    "duration": 3200,
    "start_time": "2023-08-10T16:02:08.149Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-10T16:02:11.355Z"
   },
   {
    "duration": 313,
    "start_time": "2023-08-10T16:02:11.402Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-10T16:02:11.723Z"
   },
   {
    "duration": 8554,
    "start_time": "2023-08-10T16:02:11.739Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-10T16:02:20.295Z"
   },
   {
    "duration": 60,
    "start_time": "2023-08-10T16:02:20.318Z"
   },
   {
    "duration": 8379,
    "start_time": "2023-08-10T16:02:20.380Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-10T16:02:28.761Z"
   },
   {
    "duration": 194,
    "start_time": "2023-08-10T16:02:28.768Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-10T16:02:28.964Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-10T16:03:14.899Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-10T16:05:40.065Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-10T16:05:42.620Z"
   },
   {
    "duration": 114,
    "start_time": "2023-08-10T16:05:45.377Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-10T16:05:48.517Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-10T16:06:15.687Z"
   },
   {
    "duration": 341,
    "start_time": "2023-08-10T16:09:06.265Z"
   },
   {
    "duration": 13064,
    "start_time": "2023-08-10T16:10:28.470Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-10T16:16:15.034Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-10T16:16:30.467Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-10T16:18:41.662Z"
   },
   {
    "duration": 208770,
    "start_time": "2023-08-10T16:20:50.959Z"
   },
   {
    "duration": 47,
    "start_time": "2023-08-10T16:26:46.019Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-10T16:27:25.888Z"
   },
   {
    "duration": 1430393,
    "start_time": "2023-08-10T16:27:44.381Z"
   },
   {
    "duration": 204609,
    "start_time": "2023-08-10T16:51:34.781Z"
   },
   {
    "duration": 20298,
    "start_time": "2023-08-10T16:54:59.420Z"
   },
   {
    "duration": 804169,
    "start_time": "2023-08-10T16:55:22.030Z"
   },
   {
    "duration": 78,
    "start_time": "2023-08-10T18:15:45.677Z"
   },
   {
    "duration": 4610,
    "start_time": "2023-08-10T18:16:14.425Z"
   },
   {
    "duration": 5877,
    "start_time": "2023-08-10T18:16:19.037Z"
   },
   {
    "duration": 47,
    "start_time": "2023-08-10T18:16:29.126Z"
   },
   {
    "duration": 384,
    "start_time": "2023-08-10T18:16:32.053Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-10T18:16:34.887Z"
   },
   {
    "duration": 11651,
    "start_time": "2023-08-10T18:16:41.103Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-10T18:16:55.141Z"
   },
   {
    "duration": 103,
    "start_time": "2023-08-10T18:17:02.924Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-10T18:17:05.496Z"
   },
   {
    "duration": 166,
    "start_time": "2023-08-10T18:17:11.484Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-10T18:17:14.036Z"
   },
   {
    "duration": 18199,
    "start_time": "2023-08-10T18:17:17.107Z"
   },
   {
    "duration": 185,
    "start_time": "2023-08-10T18:18:13.506Z"
   },
   {
    "duration": 43,
    "start_time": "2023-08-10T18:20:45.007Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-10T18:21:35.375Z"
   },
   {
    "duration": 25,
    "start_time": "2023-08-10T18:21:55.040Z"
   },
   {
    "duration": 182,
    "start_time": "2023-08-10T18:22:47.983Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-10T18:23:59.002Z"
   },
   {
    "duration": 37075,
    "start_time": "2023-08-10T18:24:07.482Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-10T18:26:13.292Z"
   },
   {
    "duration": 268514,
    "start_time": "2023-08-10T18:31:27.265Z"
   },
   {
    "duration": 97,
    "start_time": "2023-08-10T19:05:49.505Z"
   },
   {
    "duration": 2836,
    "start_time": "2023-08-10T19:07:36.768Z"
   },
   {
    "duration": 4010,
    "start_time": "2023-08-10T19:07:39.607Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-10T19:07:43.630Z"
   },
   {
    "duration": 360,
    "start_time": "2023-08-10T19:07:43.673Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-10T19:07:44.036Z"
   },
   {
    "duration": 9448,
    "start_time": "2023-08-10T19:07:44.051Z"
   },
   {
    "duration": 32,
    "start_time": "2023-08-10T19:07:53.501Z"
   },
   {
    "duration": 79,
    "start_time": "2023-08-10T19:07:53.536Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-10T19:07:53.617Z"
   },
   {
    "duration": 118,
    "start_time": "2023-08-10T19:07:53.623Z"
   },
   {
    "duration": 29,
    "start_time": "2023-08-10T19:07:53.743Z"
   },
   {
    "duration": 14507,
    "start_time": "2023-08-10T19:07:53.778Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-10T19:08:08.287Z"
   },
   {
    "duration": 61056,
    "start_time": "2023-08-10T19:08:08.291Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-10T19:09:09.349Z"
   },
   {
    "duration": 195,
    "start_time": "2023-08-10T19:09:09.356Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-10T19:09:09.553Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-10T19:09:09.554Z"
   },
   {
    "duration": 5610,
    "start_time": "2023-08-10T19:09:53.696Z"
   },
   {
    "duration": 3524406,
    "start_time": "2023-08-10T19:10:16.356Z"
   },
   {
    "duration": 2589,
    "start_time": "2023-08-10T20:36:51.383Z"
   },
   {
    "duration": 3690,
    "start_time": "2023-08-10T20:36:53.975Z"
   },
   {
    "duration": 49,
    "start_time": "2023-08-10T20:37:02.400Z"
   },
   {
    "duration": 332,
    "start_time": "2023-08-10T20:37:04.742Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-10T20:37:07.256Z"
   },
   {
    "duration": 9522,
    "start_time": "2023-08-10T20:37:09.527Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-10T20:37:28.591Z"
   },
   {
    "duration": 99,
    "start_time": "2023-08-10T20:37:33.777Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-10T20:37:36.076Z"
   },
   {
    "duration": 115,
    "start_time": "2023-08-10T20:37:38.774Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-10T20:37:41.044Z"
   },
   {
    "duration": 12730,
    "start_time": "2023-08-10T20:37:47.096Z"
   },
   {
    "duration": 62838,
    "start_time": "2023-08-10T20:38:14.287Z"
   },
   {
    "duration": 277806,
    "start_time": "2023-08-10T20:39:57.187Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-10T20:45:00.596Z"
   },
   {
    "duration": 192,
    "start_time": "2023-08-10T20:49:46.403Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-10T20:49:53.238Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-10T20:50:08.060Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-10T20:50:18.253Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-10T20:51:10.669Z"
   },
   {
    "duration": 30,
    "start_time": "2023-08-10T20:51:21.836Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-10T20:51:35.481Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-10T20:52:46.838Z"
   },
   {
    "duration": 3392,
    "start_time": "2023-08-11T15:10:18.650Z"
   },
   {
    "duration": 4460,
    "start_time": "2023-08-11T15:10:24.927Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-11T15:10:34.779Z"
   },
   {
    "duration": 254,
    "start_time": "2023-08-11T15:10:37.482Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-11T15:10:43.407Z"
   },
   {
    "duration": 585,
    "start_time": "2023-08-11T15:13:54.226Z"
   },
   {
    "duration": 533,
    "start_time": "2023-08-11T15:14:19.250Z"
   },
   {
    "duration": 331,
    "start_time": "2023-08-11T15:15:27.950Z"
   },
   {
    "duration": 842,
    "start_time": "2023-08-11T15:15:41.441Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-11T15:15:46.714Z"
   },
   {
    "duration": 257,
    "start_time": "2023-08-11T15:15:49.390Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-11T15:15:56.002Z"
   },
   {
    "duration": 30684,
    "start_time": "2023-08-11T15:15:59.314Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-11T15:16:40.178Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-11T15:18:24.017Z"
   },
   {
    "duration": 864,
    "start_time": "2023-08-11T15:18:27.320Z"
   },
   {
    "duration": 31634,
    "start_time": "2023-08-11T15:18:44.864Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-11T15:19:46.606Z"
   },
   {
    "duration": 835,
    "start_time": "2023-08-11T15:20:59.414Z"
   },
   {
    "duration": 5614,
    "start_time": "2023-08-11T15:21:07.152Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-11T15:21:18.527Z"
   },
   {
    "duration": 926,
    "start_time": "2023-08-11T15:21:53.633Z"
   },
   {
    "duration": 102,
    "start_time": "2023-08-11T15:27:36.092Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-11T15:29:11.244Z"
   },
   {
    "duration": 56,
    "start_time": "2023-08-11T15:29:14.186Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-11T15:29:16.896Z"
   },
   {
    "duration": 9943,
    "start_time": "2023-08-11T15:29:26.395Z"
   },
   {
    "duration": 52305,
    "start_time": "2023-08-11T15:30:13.454Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-11T15:33:20.257Z"
   },
   {
    "duration": 50483,
    "start_time": "2023-08-11T15:34:24.776Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-11T15:35:28.165Z"
   },
   {
    "duration": 6039,
    "start_time": "2023-08-11T15:38:21.305Z"
   },
   {
    "duration": 6580,
    "start_time": "2023-08-11T15:38:57.431Z"
   },
   {
    "duration": 6553,
    "start_time": "2023-08-11T15:39:41.541Z"
   },
   {
    "duration": 847,
    "start_time": "2023-08-11T15:40:10.982Z"
   },
   {
    "duration": 31479,
    "start_time": "2023-08-11T15:40:18.381Z"
   },
   {
    "duration": 61,
    "start_time": "2023-08-11T15:41:16.239Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-11T15:41:19.363Z"
   },
   {
    "duration": 47,
    "start_time": "2023-08-11T15:41:23.065Z"
   },
   {
    "duration": 10307,
    "start_time": "2023-08-11T15:41:30.613Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-11T15:41:45.590Z"
   },
   {
    "duration": 52039,
    "start_time": "2023-08-11T15:42:08.143Z"
   },
   {
    "duration": 3327,
    "start_time": "2023-08-11T15:43:36.498Z"
   },
   {
    "duration": 59717,
    "start_time": "2023-08-11T15:44:08.230Z"
   },
   {
    "duration": 52,
    "start_time": "2023-08-11T15:45:20.506Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-11T15:45:31.018Z"
   },
   {
    "duration": 49,
    "start_time": "2023-08-11T15:45:33.740Z"
   },
   {
    "duration": 9771,
    "start_time": "2023-08-11T15:45:40.575Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-11T15:45:55.737Z"
   },
   {
    "duration": 49421,
    "start_time": "2023-08-11T15:46:27.651Z"
   },
   {
    "duration": 49,
    "start_time": "2023-08-11T15:47:38.288Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-11T15:47:41.649Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-11T15:47:47.854Z"
   },
   {
    "duration": 8805,
    "start_time": "2023-08-11T15:47:50.489Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-11T15:48:11.594Z"
   },
   {
    "duration": 42,
    "start_time": "2023-08-11T15:48:40.995Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-11T15:48:44.972Z"
   },
   {
    "duration": 72,
    "start_time": "2023-08-11T15:48:51.118Z"
   },
   {
    "duration": 11195,
    "start_time": "2023-08-11T15:48:54.089Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-11T15:49:11.950Z"
   },
   {
    "duration": 53768,
    "start_time": "2023-08-11T15:49:25.718Z"
   },
   {
    "duration": 4387,
    "start_time": "2023-08-11T15:50:30.005Z"
   },
   {
    "duration": 245374,
    "start_time": "2023-08-11T15:50:43.453Z"
   },
   {
    "duration": 3023472,
    "start_time": "2023-08-11T15:55:13.100Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-11T16:51:32.819Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-11T16:53:50.195Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-11T16:56:52.279Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
